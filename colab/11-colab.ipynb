{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "v0_caBv3uJCn"
   },
   "source": [
    "# 11 어텐션의 핵심 원리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3n6fxgcwuJCu"
   },
   "source": [
    "### 실습: 어텐션의 핵심 원리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "nevncdxVuJCv",
    "outputId": "2a6d1aaa-e54e-4b96-c4ad-c0302717048d",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "임베딩 행렬의 형태: (3, 5, 512)\n",
      "쿼리 행렬의 형태: (3, 5, 64)\n",
      "키 행렬의 형태: (3, 64, 5)\n",
      "밸류 행렬의 형태: (3, 5, 64)\n",
      "어텐션 이전의 임베딩 테이블 중 '커피', '한잔', '어때' 토큰의 평균 값:\n",
      "[0.5043 0.5035 0.4792]\n",
      "어텐션 이후의 결과 중 '커피', '한잔', '어때' 토큰의 평균 값:\n",
      "[0.5063 0.5049 0.5016]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 전체 출력 형식을 소수점 이하 네 자리로 설정\n",
    "np.set_printoptions(precision=4, suppress=True)\n",
    "\n",
    "# 단어와 해당 임베딩 벡터를 딕셔너리로 정의합니다.\n",
    "embedding_dict = {\n",
    "    '<sos>': np.random.rand(512),\n",
    "    '<eos>': np.random.rand(512),\n",
    "    '커피': np.random.rand(512),\n",
    "    '한잔': np.random.rand(512),\n",
    "    '어때': np.random.rand(512),\n",
    "    '오늘': np.random.rand(512),\n",
    "    '날씨': np.random.rand(512),\n",
    "    '좋네': np.random.rand(512),\n",
    "    '옷이': np.random.rand(512),\n",
    "    '어울려요': np.random.rand(512),\n",
    "    'PAD': np.zeros(512)  # 패딩 벡터는 0으로 채웁니다.\n",
    "}\n",
    "\n",
    "# 입력 문장\n",
    "sentences = [\n",
    "    ['<sos>', '커피', '한잔', '어때', '<eos>'],\n",
    "    ['<sos>', '오늘', '날씨', '좋네', '<eos>'],\n",
    "    ['<sos>', '옷이', '어울려요', '<eos>', 'PAD']\n",
    "]\n",
    "max_len = 6  # 최대 문장 길이\n",
    "\n",
    "# 토큰을 임베딩 벡터로 변환\n",
    "embeddings = np.array([[embedding_dict[token] for token in sentence] for sentence in sentences])\n",
    "print(\"임베딩 행렬의 형태:\", embeddings.shape)  # (3, 6, 512)\n",
    "\n",
    "# 쿼리, 키, 밸류 행렬 초기화\n",
    "num_heads = 8\n",
    "head_dim = 512 // num_heads  # 각 헤드의 차원\n",
    "heads = np.split(embeddings, num_heads, axis=2)  # 512차원 임베딩 벡터를 8개의 헤드로 분할하여 heads에 저장\n",
    "queries = heads.copy()\n",
    "keys = [head.transpose(0, 2, 1) for head in heads]  # 키 행렬을 각 헤드의 전치를 통해 초기화 (첫 번째 축: 배치 크기, 두 번째 축: 문장 길이, 세 번째 축: 헤드 차원)\n",
    "values = heads.copy()\n",
    "\n",
    "print(\"쿼리 행렬의 형태:\", queries[0].shape)  # (3, 6, 64)\n",
    "print(\"키 행렬의 형태:\", keys[0].shape)  # (3, 64, 6)\n",
    "print(\"밸류 행렬의 형태:\", values[0].shape)  # (3, 6, 64)\n",
    "\n",
    "# 특정 토큰 (커피, 한잔, 어때)의 인덱스\n",
    "tokens_of_interest = ['커피', '한잔', '어때']\n",
    "indices_of_interest = [sentences[0].index(token) for token in tokens_of_interest]\n",
    "\n",
    "# 어텐션 이전의 임베딩 테이블 중 특정 토큰들의 평균 값 계산\n",
    "print(\"어텐션 이전의 임베딩 테이블 중 '커피', '한잔', '어때' 토큰의 평균 값:\")\n",
    "initial_avg = np.mean(embeddings[0, indices_of_interest, :], axis=1)\n",
    "print(initial_avg)\n",
    "\n",
    "# 스케일링 및 어텐션 스코어 계산\n",
    "attention_scores = np.matmul(queries[0], keys[0])\n",
    "scaling_factor = np.sqrt(head_dim)\n",
    "scaled_attention_scores = attention_scores / scaling_factor\n",
    "\n",
    "# 패딩 처리\n",
    "mask = np.array([[token == 'PAD' for token in sentence] for sentence in sentences])\n",
    "mask = mask[:, np.newaxis, :]  # 차원을 맞추기 위해 확장\n",
    "scaled_attention_scores = np.where(mask, -np.inf, scaled_attention_scores)\n",
    "\n",
    "# 소프트맥스 적용 함수\n",
    "def softmax(x):\n",
    "    exp_x = np.exp(x - np.max(x, axis=-1, keepdims=True))\n",
    "    return exp_x / np.sum(exp_x, axis=-1, keepdims=True)\n",
    "\n",
    "# 복원된 헤드를 저장할 리스트\n",
    "restored_heads = []\n",
    "\n",
    "for i in range(num_heads):\n",
    "    query = queries[i]\n",
    "    key = keys[i]\n",
    "    value = values[i]\n",
    "    \n",
    "    # 내적 계산 후 스케일링\n",
    "    attention_scores = np.matmul(query, key) / scaling_factor\n",
    "    \n",
    "    # 패딩 처리\n",
    "    mask = np.array([[token == 'PAD' for token in sentence] for sentence in sentences])\n",
    "    mask = mask[:, np.newaxis, :]  # 차원을 맞추기 위해 확장\n",
    "    attention_scores = np.where(mask, -np.inf, attention_scores)\n",
    "    \n",
    "    # 소프트맥스 적용\n",
    "    attention_weights = softmax(attention_scores)\n",
    "    \n",
    "    # 밸류와의 곱셈\n",
    "    restored_head = np.matmul(attention_weights, value)\n",
    "    restored_heads.append(restored_head)\n",
    "\n",
    "# 모든 헤드를 결합하여 원래 차원으로 복원\n",
    "final_output = np.concatenate(restored_heads, axis=2)\n",
    "\n",
    "# 어텐션 이후의 결과 중 특정 토큰들의 평균 값 계산\n",
    "print(\"어텐션 이후의 결과 중 '커피', '한잔', '어때' 토큰의 평균 값:\")\n",
    "final_avg = np.mean(final_output[0, indices_of_interest, :], axis=1)\n",
    "print(final_avg)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "12-colab.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
