{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "v0_caBv3uJCn"
   },
   "source": [
    "# 6교시 3.트랜스포머의 활용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "nevncdxVuJCv",
    "outputId": "2a6d1aaa-e54e-4b96-c4ad-c0302717048d",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "100/100 [==============================] - 3s 19ms/step - loss: 0.7871 - accuracy: 0.5281 - val_loss: 0.6386 - val_accuracy: 0.9950\n",
      "Epoch 2/10\n",
      "100/100 [==============================] - 2s 17ms/step - loss: 0.2017 - accuracy: 0.9400 - val_loss: 0.0031 - val_accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "100/100 [==============================] - 2s 16ms/step - loss: 0.0434 - accuracy: 0.9931 - val_loss: 0.0114 - val_accuracy: 0.9975\n",
      "Epoch 4/10\n",
      "100/100 [==============================] - 2s 16ms/step - loss: 0.0269 - accuracy: 0.9962 - val_loss: 0.0174 - val_accuracy: 0.9975\n",
      "Epoch 5/10\n",
      "100/100 [==============================] - 2s 16ms/step - loss: 0.0194 - accuracy: 0.9975 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "100/100 [==============================] - 2s 16ms/step - loss: 0.0170 - accuracy: 0.9956 - val_loss: 0.0088 - val_accuracy: 0.9950\n",
      "Epoch 7/10\n",
      "100/100 [==============================] - 2s 16ms/step - loss: 0.0099 - accuracy: 0.9994 - val_loss: 0.0025 - val_accuracy: 0.9975\n",
      "Epoch 8/10\n",
      "100/100 [==============================] - 2s 16ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0131 - val_accuracy: 0.9975\n",
      "Epoch 9/10\n",
      "100/100 [==============================] - 2s 15ms/step - loss: 0.0155 - accuracy: 0.9956 - val_loss: 0.0106 - val_accuracy: 0.9975\n",
      "Epoch 10/10\n",
      "100/100 [==============================] - 2s 16ms/step - loss: 0.0045 - accuracy: 0.9994 - val_loss: 0.0485 - val_accuracy: 0.9900\n",
      "1/1 [==============================] - 0s 168ms/step\n",
      "Text: I absolutely love this!\n",
      "Prediction: Positive\n",
      "Text: I can't stand this product\n",
      "Prediction: Negative\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Embedding, GlobalAveragePooling1D, LayerNormalization, Dropout, Add, Input, Lambda\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 깃허브에 준비된 데이터를 가져옵니다.\n",
    "!git clone https://github.com/taehojo/data.git\n",
    "\n",
    "# CSV 파일 로드\n",
    "dataframe = pd.read_csv('./data/sentiment_data.csv')\n",
    "\n",
    "# 데이터와 라벨 추출\n",
    "sentences = dataframe['sentence'].tolist()\n",
    "labels = dataframe['label'].tolist()\n",
    "\n",
    "# 임베딩 벡터 크기와 최대 문장 길이 설정\n",
    "embedding_dim = 128\n",
    "max_len = 10\n",
    "\n",
    "# 토크나이저 초기화 및 텍스트를 시퀀스로 변환\n",
    "tokenizer = tf.keras.preprocessing.text.Tokenizer()\n",
    "tokenizer.fit_on_texts(sentences)\n",
    "sequences = tokenizer.texts_to_sequences(sentences)\n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "# 패딩을 사용하여 시퀀스 길이를 동일하게 맞춤\n",
    "data = tf.keras.preprocessing.sequence.pad_sequences(sequences, maxlen=max_len, padding='post')\n",
    "\n",
    "# 데이터셋을 훈련 세트와 검증 세트로 분리\n",
    "X_train, X_val, y_train, y_val = train_test_split(data, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# 포지셔널 인코딩 함수\n",
    "def get_positional_encoding(max_len, d_model):\n",
    "    pos_enc = np.zeros((max_len, d_model))\n",
    "    for pos in range(max_len):\n",
    "        for i in range(0, d_model, 2):\n",
    "            pos_enc[pos, i] = np.sin(pos / (10000 ** (2 * i / d_model)))\n",
    "            if i + 1 < d_model:\n",
    "                pos_enc[pos, i + 1] = np.cos(pos / (10000 ** (2 * (i + 1) / d_model)))\n",
    "    return pos_enc\n",
    "\n",
    "# 포지셔널 인코딩 생성\n",
    "positional_encoding = get_positional_encoding(max_len, embedding_dim)\n",
    "\n",
    "# 멀티헤드 어텐션 레이어\n",
    "class MultiHeadSelfAttentionLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_heads, key_dim, masked=False):\n",
    "        super(MultiHeadSelfAttentionLayer, self).__init__()\n",
    "        self.mha = tf.keras.layers.MultiHeadAttention(num_heads=num_heads, key_dim=key_dim)\n",
    "        self.norm = LayerNormalization()\n",
    "        self.masked = masked  # 새롭게 추가된 부분\n",
    "\n",
    "    def call(self, x):\n",
    "        if self.masked:\n",
    "            # 마스크드 어텐션을 적용할 경우\n",
    "            batch_size = tf.shape(x)[0]  # 입력 x의 배치 크기\n",
    "            seq_len = tf.shape(x)[1]     # 입력 x의 시퀀스 길이\n",
    "    \n",
    "            # 마스크 행렬 생성\n",
    "            mask = tf.linalg.band_part(tf.ones((seq_len, seq_len)), -1, 0)  #tf.linalg.band_part: 대각선 이전 값들을 1로 채우고 나머지는 0으로\n",
    "            mask = tf.reshape(mask, (1, 1, seq_len, seq_len))  \n",
    "            # 마스크 행렬의 형태를 만들어 주는 부분 -->    # 만약 [1, 1, 4, 4] 라면\n",
    "                                                        # [[1, 0, 0, 0],\n",
    "                                                        #  [1, 1, 0, 0],\n",
    "                                                        #  [1, 1, 1, 0],\n",
    "                                                        #  [1, 1, 1, 1]] 이런 형태로 변환됨\n",
    "            \n",
    "            mask = tf.tile(mask, [batch_size, 1, 1, 1])  # 배치 크기만큼 마스크를 반복하여 확장\n",
    "            \n",
    "            # 마스크 행렬을 -무한대로 변경\n",
    "            mask = mask * -1e9\n",
    "    \n",
    "            # 마스크를 사용한 멀티헤드 어텐션\n",
    "            attn_output = self.mha(query=x, value=x, key=x, attention_mask=mask)\n",
    "        else:\n",
    "            # 마스크 없이 멀티헤드 어텐션을 적용할 경우\n",
    "            attn_output = self.mha(query=x, value=x, key=x)\n",
    "\n",
    "        attn_output = self.norm(attn_output + x) # 잔차 연결 적용 후 레이어 정규화\n",
    "        \n",
    "        return attn_output\n",
    "\n",
    "# 모델 설정\n",
    "inputs = Input(shape=(max_len,))\n",
    "\n",
    "# 1. 임베딩 레이어: 텍스트 데이터를 임베딩 벡터로 변환합니다.\n",
    "embedding_layer = Embedding(input_dim=len(word_index) + 1, output_dim=embedding_dim, input_length=max_len)\n",
    "embedded_sequences = embedding_layer(inputs)\n",
    "\n",
    "# 2. 포지셔널 인코딩 추가\n",
    "embedded_sequences_with_positional_encoding = embedded_sequences + positional_encoding\n",
    "\n",
    "# 3. 멀티헤드 어텐션 레이어 추가\n",
    "attention_layer = MultiHeadSelfAttentionLayer(num_heads=8, key_dim=embedding_dim)\n",
    "attention_output = attention_layer(embedded_sequences_with_positional_encoding)\n",
    "\n",
    "# 4. 잔차 연결\n",
    "attention_output_with_residual = Add()([embedded_sequences_with_positional_encoding, attention_output])\n",
    "\n",
    "# 5. 마스크드 멀티헤드 어텐션 레이어 추가 \n",
    "masked_attention_layer = MultiHeadSelfAttentionLayer(num_heads=8, key_dim=embedding_dim, masked=True)  # masked=True 적용\n",
    "masked_attention_output = masked_attention_layer(attention_output_with_residual)\n",
    "\n",
    "# 6. 잔차 연결\n",
    "masked_attention_output_with_residual = Add()([attention_output_with_residual, masked_attention_output])\n",
    "\n",
    "# 7. GlobalAveragePooling1D 레이어 추가\n",
    "pooled_output = GlobalAveragePooling1D()(masked_attention_output_with_residual)\n",
    "\n",
    "# 8. 피드 포워드 네트워크\n",
    "dense_layer = Dense(128, activation='relu')(pooled_output)\n",
    "dropout_layer = Dropout(0.5)(dense_layer)\n",
    "output_layer = Dense(1, activation='sigmoid')(dropout_layer)\n",
    "\n",
    "# 모델 생성\n",
    "model = Model(inputs=inputs, outputs=output_layer)\n",
    "\n",
    "# 모델 컴파일\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# 모델 학습\n",
    "history = model.fit(X_train, np.array(y_train), epochs=10, batch_size=16, validation_data=(X_val, np.array(y_val)))\n",
    "\n",
    "# 샘플 데이터 예측\n",
    "sample_texts = [\"I absolutely love this!\", \"I can't stand this product\"]\n",
    "sample_sequences = tokenizer.texts_to_sequences(sample_texts)\n",
    "sample_data = tf.keras.preprocessing.sequence.pad_sequences(sample_sequences, maxlen=max_len, padding='post')\n",
    "predictions = model.predict(sample_data)\n",
    "\n",
    "for i, text in enumerate(sample_texts):\n",
    "    print(f\"Text: {text}\")\n",
    "    print(f\"Prediction: {'Positive' if predictions[i] > 0.5 else 'Negative'}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<참고 도표> \n",
    "데이터 특성과 모델 복잡성에 따라 마스크드 어텐션의 사용 여부를 결정해 최적의 모델을 선택하는 것이 중요합니다. 특히 마스크드 어텐션은 문장 순서가 중요한 경우에 유리합니다. 주어진 샘플의 경우, 아래와 같이 샘플 수를 줄이면 마스크드 어텐션 유무의 차이가 더욱 두드러지게 나타납니다. 이러한 요소가 주어진 데이터의 분석 성능을 향상시킬 수 있습니다.\n",
    "\n",
    "<img src=\"../data/img/validation_accuracy_comparison_smooth.png\" alt=\"Validation Accuracy Comparison\" width=\"600\"/>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "12-colab.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
