{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "P0I8HGxUw97B"
   },
   "source": [
    "# 4교시 2. CNN과 전이학습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J-dqKaIPw97E"
   },
   "source": [
    "## 1. 소규모 데이터셋으로 만드는 강력한 학습 모델"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HSlfKpYlw97F"
   },
   "source": [
    "### 치매 환자의 뇌인지 일반인의 뇌인지 예측하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "xP-yRE_nw97F",
    "outputId": "de2473fb-b51f-4e9f-ca58-749a5f3f811a",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 160 images belonging to 2 classes.\n",
      "Found 120 images belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into 'data-ch20'...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.7001 - accuracy: 0.5625\n",
      "Epoch 1: val_loss improved from inf to 0.68770, saving model to ./data-ch20\\MNIST_CNN.hdf5\n",
      "32/32 [==============================] - 5s 124ms/step - loss: 0.7001 - accuracy: 0.5625 - val_loss: 0.6877 - val_accuracy: 0.5000\n",
      "Epoch 2/30\n",
      " 1/32 [..............................] - ETA: 2s - loss: 0.6853 - accuracy: 0.6000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taehj\\anaconda3\\envs\\tf24\\lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - ETA: 0s - loss: 0.6973 - accuracy: 0.5375\n",
      "Epoch 2: val_loss did not improve from 0.68770\n",
      "32/32 [==============================] - 2s 76ms/step - loss: 0.6973 - accuracy: 0.5375 - val_loss: 0.6889 - val_accuracy: 0.5000\n",
      "Epoch 3/30\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.7058 - accuracy: 0.5437\n",
      "Epoch 3: val_loss improved from 0.68770 to 0.68666, saving model to ./data-ch20\\MNIST_CNN.hdf5\n",
      "32/32 [==============================] - 2s 71ms/step - loss: 0.7058 - accuracy: 0.5437 - val_loss: 0.6867 - val_accuracy: 0.5333\n",
      "Epoch 4/30\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.6911 - accuracy: 0.5437\n",
      "Epoch 4: val_loss improved from 0.68666 to 0.68090, saving model to ./data-ch20\\MNIST_CNN.hdf5\n",
      "32/32 [==============================] - 2s 75ms/step - loss: 0.6911 - accuracy: 0.5437 - val_loss: 0.6809 - val_accuracy: 0.5000\n",
      "Epoch 5/30\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.6866 - accuracy: 0.5875\n",
      "Epoch 5: val_loss improved from 0.68090 to 0.68071, saving model to ./data-ch20\\MNIST_CNN.hdf5\n",
      "32/32 [==============================] - 2s 74ms/step - loss: 0.6866 - accuracy: 0.5875 - val_loss: 0.6807 - val_accuracy: 0.5250\n",
      "Epoch 6/30\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.6791 - accuracy: 0.6125\n",
      "Epoch 6: val_loss improved from 0.68071 to 0.60151, saving model to ./data-ch20\\MNIST_CNN.hdf5\n",
      "32/32 [==============================] - 2s 76ms/step - loss: 0.6791 - accuracy: 0.6125 - val_loss: 0.6015 - val_accuracy: 0.7667\n",
      "Epoch 7/30\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.6410 - accuracy: 0.6500\n",
      "Epoch 7: val_loss improved from 0.60151 to 0.56460, saving model to ./data-ch20\\MNIST_CNN.hdf5\n",
      "32/32 [==============================] - 3s 77ms/step - loss: 0.6410 - accuracy: 0.6500 - val_loss: 0.5646 - val_accuracy: 0.6667\n",
      "Epoch 8/30\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.6004 - accuracy: 0.6875\n",
      "Epoch 8: val_loss improved from 0.56460 to 0.45471, saving model to ./data-ch20\\MNIST_CNN.hdf5\n",
      "32/32 [==============================] - 2s 74ms/step - loss: 0.6004 - accuracy: 0.6875 - val_loss: 0.4547 - val_accuracy: 0.8500\n",
      "Epoch 9/30\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.5148 - accuracy: 0.7250\n",
      "Epoch 9: val_loss did not improve from 0.45471\n",
      "32/32 [==============================] - 2s 74ms/step - loss: 0.5148 - accuracy: 0.7250 - val_loss: 0.4577 - val_accuracy: 0.8583\n",
      "Epoch 10/30\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.4589 - accuracy: 0.7812\n",
      "Epoch 10: val_loss improved from 0.45471 to 0.40025, saving model to ./data-ch20\\MNIST_CNN.hdf5\n",
      "32/32 [==============================] - 2s 76ms/step - loss: 0.4589 - accuracy: 0.7812 - val_loss: 0.4002 - val_accuracy: 0.8167\n",
      "Epoch 11/30\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.3433 - accuracy: 0.8438\n",
      "Epoch 11: val_loss improved from 0.40025 to 0.25018, saving model to ./data-ch20\\MNIST_CNN.hdf5\n",
      "32/32 [==============================] - 2s 75ms/step - loss: 0.3433 - accuracy: 0.8438 - val_loss: 0.2502 - val_accuracy: 0.8917\n",
      "Epoch 12/30\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.3420 - accuracy: 0.8562\n",
      "Epoch 12: val_loss improved from 0.25018 to 0.24388, saving model to ./data-ch20\\MNIST_CNN.hdf5\n",
      "32/32 [==============================] - 2s 72ms/step - loss: 0.3420 - accuracy: 0.8562 - val_loss: 0.2439 - val_accuracy: 0.9333\n",
      "Epoch 13/30\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.2820 - accuracy: 0.8750\n",
      "Epoch 13: val_loss improved from 0.24388 to 0.17000, saving model to ./data-ch20\\MNIST_CNN.hdf5\n",
      "32/32 [==============================] - 2s 78ms/step - loss: 0.2820 - accuracy: 0.8750 - val_loss: 0.1700 - val_accuracy: 0.9333\n",
      "Epoch 14/30\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.2349 - accuracy: 0.9062\n",
      "Epoch 14: val_loss did not improve from 0.17000\n",
      "32/32 [==============================] - 2s 76ms/step - loss: 0.2349 - accuracy: 0.9062 - val_loss: 0.3399 - val_accuracy: 0.8083\n",
      "Epoch 15/30\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.2277 - accuracy: 0.9312\n",
      "Epoch 15: val_loss improved from 0.17000 to 0.15919, saving model to ./data-ch20\\MNIST_CNN.hdf5\n",
      "32/32 [==============================] - 3s 81ms/step - loss: 0.2277 - accuracy: 0.9312 - val_loss: 0.1592 - val_accuracy: 0.9333\n",
      "Epoch 16/30\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.1470 - accuracy: 0.9312\n",
      "Epoch 16: val_loss improved from 0.15919 to 0.09454, saving model to ./data-ch20\\MNIST_CNN.hdf5\n",
      "32/32 [==============================] - 2s 72ms/step - loss: 0.1470 - accuracy: 0.9312 - val_loss: 0.0945 - val_accuracy: 0.9583\n",
      "Epoch 17/30\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.1467 - accuracy: 0.9563\n",
      "Epoch 17: val_loss did not improve from 0.09454\n",
      "32/32 [==============================] - 2s 74ms/step - loss: 0.1467 - accuracy: 0.9563 - val_loss: 0.2542 - val_accuracy: 0.8917\n",
      "Epoch 18/30\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.1363 - accuracy: 0.9438\n",
      "Epoch 18: val_loss did not improve from 0.09454\n",
      "32/32 [==============================] - 2s 74ms/step - loss: 0.1363 - accuracy: 0.9438 - val_loss: 0.1778 - val_accuracy: 0.9250\n",
      "Epoch 19/30\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.1341 - accuracy: 0.9563\n",
      "Epoch 19: val_loss improved from 0.09454 to 0.08701, saving model to ./data-ch20\\MNIST_CNN.hdf5\n",
      "32/32 [==============================] - 3s 80ms/step - loss: 0.1341 - accuracy: 0.9563 - val_loss: 0.0870 - val_accuracy: 0.9667\n",
      "Epoch 20/30\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.1122 - accuracy: 0.9625\n",
      "Epoch 20: val_loss improved from 0.08701 to 0.07131, saving model to ./data-ch20\\MNIST_CNN.hdf5\n",
      "32/32 [==============================] - 3s 80ms/step - loss: 0.1122 - accuracy: 0.9625 - val_loss: 0.0713 - val_accuracy: 0.9750\n",
      "Epoch 21/30\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.1146 - accuracy: 0.9625\n",
      "Epoch 21: val_loss did not improve from 0.07131\n",
      "32/32 [==============================] - 2s 70ms/step - loss: 0.1146 - accuracy: 0.9625 - val_loss: 0.0725 - val_accuracy: 0.9833\n",
      "Epoch 22/30\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.1009 - accuracy: 0.9625\n",
      "Epoch 22: val_loss did not improve from 0.07131\n",
      "32/32 [==============================] - 2s 68ms/step - loss: 0.1009 - accuracy: 0.9625 - val_loss: 0.2027 - val_accuracy: 0.9083\n",
      "Epoch 23/30\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.1295 - accuracy: 0.9688\n",
      "Epoch 23: val_loss did not improve from 0.07131\n",
      "32/32 [==============================] - 2s 77ms/step - loss: 0.1295 - accuracy: 0.9688 - val_loss: 0.1463 - val_accuracy: 0.9417\n",
      "Epoch 24/30\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.0588 - accuracy: 0.9812\n",
      "Epoch 24: val_loss did not improve from 0.07131\n",
      "32/32 [==============================] - 2s 77ms/step - loss: 0.0588 - accuracy: 0.9812 - val_loss: 0.1412 - val_accuracy: 0.9417\n",
      "Epoch 25/30\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.0748 - accuracy: 0.9688\n",
      "Epoch 25: val_loss did not improve from 0.07131\n",
      "32/32 [==============================] - 2s 77ms/step - loss: 0.0748 - accuracy: 0.9688 - val_loss: 0.1844 - val_accuracy: 0.9250\n",
      "Epoch 26/30\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.0965 - accuracy: 0.9688\n",
      "Epoch 26: val_loss improved from 0.07131 to 0.06074, saving model to ./data-ch20\\MNIST_CNN.hdf5\n",
      "32/32 [==============================] - 3s 79ms/step - loss: 0.0965 - accuracy: 0.9688 - val_loss: 0.0607 - val_accuracy: 0.9833\n",
      "Epoch 27/30\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.1188 - accuracy: 0.9625\n",
      "Epoch 27: val_loss did not improve from 0.06074\n",
      "32/32 [==============================] - 3s 85ms/step - loss: 0.1188 - accuracy: 0.9625 - val_loss: 0.0775 - val_accuracy: 0.9667\n",
      "Epoch 28/30\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.0676 - accuracy: 0.9750\n",
      "Epoch 28: val_loss did not improve from 0.06074\n",
      "32/32 [==============================] - 2s 72ms/step - loss: 0.0676 - accuracy: 0.9750 - val_loss: 0.0626 - val_accuracy: 0.9833\n",
      "Epoch 29/30\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.0800 - accuracy: 0.9625\n",
      "Epoch 29: val_loss improved from 0.06074 to 0.04410, saving model to ./data-ch20\\MNIST_CNN.hdf5\n",
      "32/32 [==============================] - 2s 72ms/step - loss: 0.0800 - accuracy: 0.9625 - val_loss: 0.0441 - val_accuracy: 0.9833\n",
      "Epoch 30/30\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.0708 - accuracy: 0.9750\n",
      "Epoch 30: val_loss did not improve from 0.04410\n",
      "32/32 [==============================] - 2s 74ms/step - loss: 0.0708 - accuracy: 0.9750 - val_loss: 0.1279 - val_accuracy: 0.9500\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 0.1279 - accuracy: 0.9500\n",
      "\n",
      " Test Accuracy: 0.9500\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, Activation\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras import optimizers\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 깃허브에 준비된 데이터를 가져옵니다.\n",
    "!git clone https://github.com/taehojo/data-ch20.git\n",
    "\n",
    "# 학습셋의 변형을 설정하는 부분입니다. \n",
    "train_datagen = ImageDataGenerator(rescale=1./255,          # 픽셀의 값을 0.0~1.0사이로 정규화합니다.\n",
    "                                  horizontal_flip=True,     # 수평 대칭 이미지를 50% 확률로 만들어 추가합니다.\n",
    "                                  width_shift_range=0.1,    # 전체 크기의 10% 범위에서 좌우로 이동합니다.\n",
    "                                  height_shift_range=0.1)   # 마찬가지로 위, 아래로 이동합니다.\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "       './data-ch20/train',   # 학습셋이 있는 폴더의 위치입니다.\n",
    "       target_size=(150, 150),\n",
    "       batch_size=5,\n",
    "       class_mode='binary')\n",
    "\n",
    "# 테스트셋은 이미지 부풀리기 과정을 진행하지 않습니다.\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)  \n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "       './data-ch20/test',   # 테스트셋이 있는 폴더의 위치입니다.\n",
    "       target_size=(150, 150),\n",
    "       batch_size=5,\n",
    "       class_mode='binary')\n",
    "\n",
    "# 앞서 배운 CNN 모델을 만들어 적용해 보겠습니다.\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), input_shape=(150, 150, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.summary()\n",
    "\n",
    "# 모델의 실행 옵션을 설정합니다.\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# 모델 최적화를 위한 설정 구간입니다.\n",
    "modelpath=\"./data-ch20/MNIST_CNN.hdf5\"\n",
    "checkpointer = ModelCheckpoint(filepath=modelpath, monitor='val_loss', verbose=1, save_best_only=True)\n",
    "early_stopping_callback = EarlyStopping(monitor='val_loss', patience=10)\n",
    "\n",
    "# 모델을 실행합니다.\n",
    "history = model.fit(train_generator, \n",
    "                    validation_data=test_generator, \n",
    "                    epochs=30, \n",
    "                    verbose=1, \n",
    "                    callbacks=[early_stopping_callback, checkpointer])\n",
    "\n",
    "# 테스트 정확도를 출력합니다.\n",
    "print(\"\\n Test Accuracy: %.4f\" % (model.evaluate(test_generator)[1]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PyEFjTCww97J"
   },
   "source": [
    "## 2. 전이 학습으로 모델 성능 극대화하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q0AiZr6nw97J"
   },
   "source": [
    "### 실습: 전이 학습 실습하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../data/img/04-04.png\" width=\"400\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "qKZwSZv8w97K",
    "outputId": "20ba6aa9-ae7b-4db7-ad02-ea8952ae0418"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 160 images belonging to 2 classes.\n",
      "Found 120 images belonging to 2 classes.\n",
      "Epoch 1/30\n",
      "32/32 [==============================] - 7s 191ms/step - loss: 0.9440 - accuracy: 0.5500 - val_loss: 0.6437 - val_accuracy: 0.5600\n",
      "Epoch 2/30\n",
      "32/32 [==============================] - 6s 192ms/step - loss: 0.5907 - accuracy: 0.6812 - val_loss: 0.4814 - val_accuracy: 0.7800\n",
      "Epoch 3/30\n",
      "32/32 [==============================] - 6s 188ms/step - loss: 0.5075 - accuracy: 0.6938 - val_loss: 0.3831 - val_accuracy: 0.9000\n",
      "Epoch 4/30\n",
      "32/32 [==============================] - 6s 194ms/step - loss: 0.3878 - accuracy: 0.8313 - val_loss: 0.3947 - val_accuracy: 0.8600\n",
      "Epoch 5/30\n",
      "32/32 [==============================] - 6s 200ms/step - loss: 0.3696 - accuracy: 0.8438 - val_loss: 0.2996 - val_accuracy: 0.9200\n",
      "Epoch 6/30\n",
      "32/32 [==============================] - 6s 203ms/step - loss: 0.3414 - accuracy: 0.8562 - val_loss: 0.3019 - val_accuracy: 0.8600\n",
      "Epoch 7/30\n",
      "32/32 [==============================] - 6s 197ms/step - loss: 0.3218 - accuracy: 0.8562 - val_loss: 0.2467 - val_accuracy: 0.9200\n",
      "Epoch 8/30\n",
      "32/32 [==============================] - 6s 201ms/step - loss: 0.2757 - accuracy: 0.9125 - val_loss: 0.2246 - val_accuracy: 0.9200\n",
      "Epoch 9/30\n",
      "32/32 [==============================] - 6s 202ms/step - loss: 0.2735 - accuracy: 0.8562 - val_loss: 0.2038 - val_accuracy: 0.9400\n",
      "Epoch 10/30\n",
      "32/32 [==============================] - 6s 203ms/step - loss: 0.2569 - accuracy: 0.9062 - val_loss: 0.1967 - val_accuracy: 0.9600\n",
      "Epoch 11/30\n",
      "32/32 [==============================] - 7s 204ms/step - loss: 0.2320 - accuracy: 0.9250 - val_loss: 0.1074 - val_accuracy: 0.9800\n",
      "Epoch 12/30\n",
      "32/32 [==============================] - 6s 201ms/step - loss: 0.2111 - accuracy: 0.9187 - val_loss: 0.0883 - val_accuracy: 0.9800\n",
      "Epoch 13/30\n",
      "32/32 [==============================] - 6s 203ms/step - loss: 0.1845 - accuracy: 0.9125 - val_loss: 0.1524 - val_accuracy: 0.9800\n",
      "Epoch 14/30\n",
      "32/32 [==============================] - 6s 197ms/step - loss: 0.2468 - accuracy: 0.9062 - val_loss: 0.1480 - val_accuracy: 0.9600\n",
      "Epoch 15/30\n",
      "32/32 [==============================] - 6s 194ms/step - loss: 0.2601 - accuracy: 0.9000 - val_loss: 0.1847 - val_accuracy: 0.9400\n",
      "Epoch 16/30\n",
      "32/32 [==============================] - 6s 193ms/step - loss: 0.2438 - accuracy: 0.8875 - val_loss: 0.1638 - val_accuracy: 0.9200\n",
      "Epoch 17/30\n",
      "32/32 [==============================] - 6s 193ms/step - loss: 0.2097 - accuracy: 0.9187 - val_loss: 0.1293 - val_accuracy: 0.9600\n",
      "Epoch 18/30\n",
      "32/32 [==============================] - 6s 194ms/step - loss: 0.2218 - accuracy: 0.9375 - val_loss: 0.1855 - val_accuracy: 0.9400\n",
      "Epoch 19/30\n",
      "32/32 [==============================] - 6s 196ms/step - loss: 0.1559 - accuracy: 0.9312 - val_loss: 0.1181 - val_accuracy: 0.9600\n",
      "Epoch 20/30\n",
      "32/32 [==============================] - 6s 193ms/step - loss: 0.1857 - accuracy: 0.9062 - val_loss: 0.3347 - val_accuracy: 0.8800\n",
      "Epoch 21/30\n",
      "32/32 [==============================] - 6s 199ms/step - loss: 0.1595 - accuracy: 0.9563 - val_loss: 0.0781 - val_accuracy: 0.9600\n",
      "Epoch 22/30\n",
      "32/32 [==============================] - 6s 200ms/step - loss: 0.2048 - accuracy: 0.9250 - val_loss: 0.2407 - val_accuracy: 0.9200\n",
      "Epoch 23/30\n",
      "32/32 [==============================] - 6s 201ms/step - loss: 0.1527 - accuracy: 0.9375 - val_loss: 0.1067 - val_accuracy: 0.9800\n",
      "Epoch 24/30\n",
      "32/32 [==============================] - 6s 201ms/step - loss: 0.1659 - accuracy: 0.9250 - val_loss: 0.0796 - val_accuracy: 1.0000\n",
      "Epoch 25/30\n",
      "32/32 [==============================] - 6s 200ms/step - loss: 0.1223 - accuracy: 0.9688 - val_loss: 0.1038 - val_accuracy: 0.9600\n",
      "Epoch 26/30\n",
      "32/32 [==============================] - 6s 200ms/step - loss: 0.1556 - accuracy: 0.9500 - val_loss: 0.2043 - val_accuracy: 0.9200\n",
      "Epoch 27/30\n",
      "32/32 [==============================] - 6s 200ms/step - loss: 0.1559 - accuracy: 0.9500 - val_loss: 0.0744 - val_accuracy: 0.9800\n",
      "Epoch 28/30\n",
      "32/32 [==============================] - 6s 201ms/step - loss: 0.1417 - accuracy: 0.9250 - val_loss: 0.1381 - val_accuracy: 0.9600\n",
      "Epoch 29/30\n",
      "32/32 [==============================] - 6s 201ms/step - loss: 0.1664 - accuracy: 0.9438 - val_loss: 0.2703 - val_accuracy: 0.9000\n",
      "Epoch 30/30\n",
      "32/32 [==============================] - 7s 208ms/step - loss: 0.1441 - accuracy: 0.9312 - val_loss: 0.0890 - val_accuracy: 0.9600\n",
      "24/24 [==============================] - 4s 148ms/step - loss: 0.0871 - accuracy: 0.9750\n",
      "\n",
      " Test Accuracy: 0.9750\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import models, layers, optimizers, callbacks\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 학습셋의 변형을 설정하는 부분입니다. \n",
    "train_datagen = ImageDataGenerator(rescale=1./255,          # 주어진 이미지의 크기를 설정합니다.\n",
    "                                  horizontal_flip=True,     # 수평 대칭 이미지를 50% 확률로 만들어 추가합니다.\n",
    "                                  width_shift_range=0.1,    # 전체 크기의 10% 범위에서 좌우로 이동합니다.\n",
    "                                  height_shift_range=0.1)   # 마찬가지로 위, 아래로 이동합니다.\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "       './data-ch20/train',\n",
    "       target_size=(150, 150),\n",
    "       batch_size=5,\n",
    "       class_mode='binary')\n",
    "\n",
    "# 테스트셋의 정규화를 설정합니다.\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "       './data-ch20/test',\n",
    "       target_size=(150, 150),\n",
    "       batch_size=5,\n",
    "       class_mode='binary')\n",
    "\n",
    "# VGG16 모델을 불러옵니다.\n",
    "transfer_model = VGG16(weights='imagenet', include_top=False, input_shape=(150, 150, 3))\n",
    "transfer_model.trainable = False\n",
    "\n",
    "# 우리의 모델을 설정합니다.\n",
    "finetune_model = models.Sequential()\n",
    "finetune_model.add(transfer_model)\n",
    "finetune_model.add(Flatten())\n",
    "finetune_model.add(Dense(64, activation='relu'))\n",
    "finetune_model.add(Dropout(0.5))\n",
    "finetune_model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# 모델의 실행 옵션을 설정합니다. \n",
    "finetune_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# 학습의 조기 중단을 설정합니다.\n",
    "early_stopping_callback = EarlyStopping(monitor='val_loss', patience=10)\n",
    "\n",
    "# 모델을 실행합니다.\n",
    "history = finetune_model.fit(\n",
    "       train_generator,\n",
    "       epochs=30,\n",
    "       validation_data=test_generator,\n",
    "       validation_steps=10, \n",
    "       callbacks=[early_stopping_callback])\n",
    "\n",
    "# 테스트 정확도를 출력합니다.\n",
    "print(\"\\n Test Accuracy: %.4f\" % (finetune_model.evaluate(test_generator)[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "08-colab.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
